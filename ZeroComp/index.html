<!-- todo page 1 -->
<!-- todo bibtex link -->

<script src="http://www.google.com/jsapi" type="text/javascript"></script>
<script type="text/javascript">google.load("jquery", "1.3.2");</script>

<style type="text/css">
	body {
		font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
		font-weight: 300;
		font-size: 18px;
		margin-left: auto;
		margin-right: auto;
		width: 1100px;
	}

	h1 {
		font-size: 32px;
		font-weight: 300;
	}

	.disclaimerbox {
		background-color: #eee;
		border: 1px solid #eeeeee;
		border-radius: 10px;
		-moz-border-radius: 10px;
		-webkit-border-radius: 10px;
		padding: 20px;
	}

	video.header-vid {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px;
		-moz-border-radius: 10px;
		-webkit-border-radius: 10px;
	}

	img.header-img {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px;
		-moz-border-radius: 10px;
		-webkit-border-radius: 10px;
	}

	img.rounded {
		border: 1px solid #eeeeee;
		border-radius: 10px;
		-moz-border-radius: 10px;
		-webkit-border-radius: 10px;
	}

	a:link,
	a:visited {
		color: #1367a7;
		text-decoration: none;
	}

	a:hover {
		color: #208799;
	}

	td.dl-link {
		height: 160px;
		text-align: center;
		font-size: 22px;
	}

	.layered-paper-big {
		/* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
			0px 0px 1px 1px rgba(0, 0, 0, 0.35),
			/* The top layer shadow */
			5px 5px 0 0px #fff,
			/* The second layer */
			5px 5px 1px 1px rgba(0, 0, 0, 0.35),
			/* The second layer shadow */
			10px 10px 0 0px #fff,
			/* The third layer */
			10px 10px 1px 1px rgba(0, 0, 0, 0.35),
			/* The third layer shadow */
			15px 15px 0 0px #fff,
			/* The fourth layer */
			15px 15px 1px 1px rgba(0, 0, 0, 0.35),
			/* The fourth layer shadow */
			20px 20px 0 0px #fff,
			/* The fifth layer */
			20px 20px 1px 1px rgba(0, 0, 0, 0.35),
			/* The fifth layer shadow */
			25px 25px 0 0px #fff,
			/* The fifth layer */
			25px 25px 1px 1px rgba(0, 0, 0, 0.35);
		/* The fifth layer shadow */
		margin-left: 10px;
		margin-right: 45px;
	}

	.paper-big {
		/* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
			0px 0px 1px 1px rgba(0, 0, 0, 0.35);
		/* The top layer shadow */

		margin-left: 10px;
		margin-right: 45px;
	}


	.layered-paper {
		/* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
			0px 0px 1px 1px rgba(0, 0, 0, 0.35),
			/* The top layer shadow */
			5px 5px 0 0px #fff,
			/* The second layer */
			5px 5px 1px 1px rgba(0, 0, 0, 0.35),
			/* The second layer shadow */
			10px 10px 0 0px #fff,
			/* The third layer */
			10px 10px 1px 1px rgba(0, 0, 0, 0.35);
		/* The third layer shadow */
		margin-top: 5px;
		margin-left: 10px;
		margin-right: 30px;
		margin-bottom: 5px;
	}

	.vert-cent {
		position: relative;
		top: 50%;
		transform: translateY(-50%);
	}

	hr {
		border: 0;
		height: 1px;
		background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
	}
</style>

<html>

<head>
	<title>ZeroComp: Zero-shot Object Compositing from Image Intrinsics via Diffusion</title>
	<meta name="description"
		content="
	ZeroComp is a zero-shot 3D object compositing method that integrates virtual objects into scenes without paired training images, using ControlNet and Stable Diffusion to adjust shading and scene interactions for realistic results, and creates realistic composites.">
	<link rel="stylesheet" href="https://fonts.googleapis.com/icon?family=Material+Icons">
	<link rel="icon" type="image/x-icon" href="./assets/favicon.ico">
</head>

<body>
	<br>
	<center>
		<br <div style="text-align:center">
		<span style="font-size:32px"> ZeroComp: Zero-shot Object Compositing from Image Intrinsics via Diffusion </span>

		</div>
		<table align=center width=600px>
			<tr>

				<td align=center>
					<center>
						<span style="font-size:20px"><a href="https://github.com/zzt76">Zitian
								Zhang</a></span>&nbsp;&nbsp;&nbsp;&nbsp;
						<span style="font-size:20px"><a href="https://www.linkedin.com/in/lefreud">Frédéric
								Fortier-Chouinard</a></span>&nbsp;&nbsp;&nbsp;&nbsp;
						<br>
						<span style="font-size:20px"><a
								href="https://scholar.google.ca/citations?user=C7ueIMwAAAAJ">Mathieu
								Garon</a></span>&nbsp;&nbsp;&nbsp;&nbsp;
						<span style="font-size:20px"><a href="https://anandbhattad.github.io/">Anand
								Bhattad</a></span>&nbsp;&nbsp;&nbsp;&nbsp;
						<span style="font-size:20px"><a href="http://www.jflalonde.ca/">Jean-François
								Lalonde</a></span>&nbsp;&nbsp;&nbsp;&nbsp;
					</center>
					<br>
					<img src="./assets/ul_logo.png" align="center" width="30%">
					<img src="./assets/depix_logo.png" align="center" width="30%">
					<img src="./assets/ttic_logo.jpg" align="center" width="30%">
					<br>
					<br>

				</td>
			</tr>
			<tr>
			</tr>
		</table>
	</center>

	<center>
		<table align=center width=850px>
			<tr>
				<td width=1000px>
					<center>
						<img class="round" style="width:1000px" src="./assets/teaser.png" />
					</center>
				</td>
			</tr>
		</table>
	</center>

	<hr>

	<table align=center width=875px>
		<table align=center width=600px>
			<tr>
				<td align=center width=120px>
					<center>
						<span style="font-size:24px"><a href='https://arxiv.org/abs/2410.08168'>[Paper]</a></span>
					</center>
				</td>
				<td align=center width=120px>
					<center>
						<span style="font-size:24px"><a href='./supp/index.html'>[Supplementary]</a></span><br>
					</center>
				</td>
				<td align=center width=120px>
					<center>
						<span style="font-size:24px"><a href='./assets/poster.pdf'>[Poster]</a></span><br>
					</center>
				</td>

				<td align=center width=120px>
					<center>
						<span style="font-size:24px"><a href='./assets/bibtex.txt'>[Bibtex]</a></span><br>
					</center>
				</td>
			</tr>
			<tr>

		</table>
	</table>

	<hr>


	<!-- <table align=center width=875px>
		<table align=center width=700px>
			<tr>
				<td align=center width=150px>
					<center>
						Accepted in <span style="font-size:20px"><a href='https://iccv2023.thecvf.com/'>International
								Conference on Computer Vision (ICCV)</a>, 2023!</span>
					</center>
				</td>
			<tr>
			<tr>
			<tr>

		</table>
	</table> -->
	<!-- <hr>
	<hr> -->

	<!-- <table align=center width=875px>
	  		  <table align=center width=700px> 
	  		  	<tr>  
	  	              <td width=150px>
	  					<center>
	  						<span style="font-size:24px">This work is featured at <a href='https://www.adobe.com/max.html'>Adobe Max Sneaks 2022</a>!</span>
		  		  		</td>
		  		  	
		  		  	</tr>
		  		  </table>
		  		  <table align=center width=700px> 

		  		  	<tr>
		  		  	<tr>
		  		  	<td> 
		  		  		Media Coverage: 
		  		  		<td> <li> <a href='https://blog.adobe.com/en/publish/2022/10/19/adobe-max-sneaks-show-how-ai-is-enhancing-future-of-creativity'>Adobe Blog</a> </li> </td>
		  		  		<td> <li> <a href='https://www.popsci.com/technology/adobe-beyond-the-seen-ai/'>Popular Science</a> </li> </td>
		  		  		<td> <li> <a href='https://petapixel.com/2022/10/20/adobe-can-use-ai-to-extend-photos-well-beyond-their-original-boundaries/'>PetaPixel</a> </li> </td>
		  		  		<td> <li> <a href='https://www.digitalcameraworld.com/news/the-future-of-photoshop-is-blowing-my-mind'>DigitalCameraWorld</a> </li> </td>
		  		  		</center>
		  		  	  </td>   
	  			  <tr>
	  			  
	  			  
			  </table>
			</table>
		  <hr> 
		  <hr> -->

	<table align=center width=875px>
		<center>
			<h1>Abstract</h1>
		</center>
		<tr>
			<td>
				We present ZeroComp, an effective zero-shot 3D object compositing approach that does not require paired
				composite-scene images during training. Our method leverages ControlNet to condition from intrinsic
				images and combines it with a Stable Diffusion model to utilize its scene priors, together operating as
				an effective rendering engine. During training, ZeroComp uses intrinsic images based on geometry,
				albedo, and masked shading, all without the need for paired images of scenes with and without composite
				objects. Once trained, it seamlessly integrates virtual 3D objects into scenes, adjusting shading to
				create realistic composites. We developed a high-quality evaluation dataset and demonstrate that
				ZeroComp outperforms methods using explicit lighting estimations and generative techniques in
				quantitative and human perception benchmarks. Additionally, ZeroComp extends to real and outdoor image
				compositing, even when trained solely on synthetic indoor data, showcasing its effectiveness in image
				compositing.
			</td>
		</tr>
	</table>

	<hr>

	<center>
		<h1>ZeroComp Pipeline</h1>
	</center>
	<table align=center hight='1200' width='800px'>
		<p align="center">
			<img src="./assets/Pipeline1_or4.png" width="100%">
	</table>

	<hr>

	<center>
		<h1>Qualitative Comparison</h1>
	</center>
	<table align=center hight='1200' width='800px'>
		<p align="center">
			<img src="./assets/results_comparison.png" width="100%">
	</table>

	<hr>

	<center>
		<h1>Extensions: Material editing</h1>
	</center>
	<table align=center hight='1200' width='800px'>
		<p align="center">
			Training ZeroComp on InteriorVerse significantly enhances its performance with shiny
			objects by allowing precise control over roughness and metallic properties.
		<p align="center">
			<img src="./assets/shiny_objects.png" width="100%">
	</table>

	<hr>

	<center>
		<h1>Extensions: Outdoor images</h1>
	</center>
	<table align=center hight='1200' width='800px'>
		<p align="center">
			ZeroComp generalizes to outdoor scenes, despite being trained exclusively on indoor scenes. Note how the
			object shading and cast shadows seamlessly blend with the target background.
		<p align="center">
			<img src="./assets/outdoor/1.jpg" width="30%">
			<img src="./assets/outdoor/2.jpg" width="30%">
			<img src="./assets/outdoor/3.jpg" width="30%">
	</table>

	<hr>

	<center>
		<h1>Extensions: 2D object compositing</h1>
	</center>
	<table align=center hight='1200' width='800px'>
		<p align="center">
			ZeroComp can also be applied to 2D objects segmented from real images, where a 3D model is not available.
			Here, we rely on intrinsic estimators to estimate the object depth and normals. We use the RGB as the albedo
			to avoid detrimental noise in the image texture while keeping the rest of the pipeline unchanged. For
			demonstration purposes, the object was segmented and placed in the target image manually. The following
			figure shows several such examples, showing our method can be easily extended to the case of 2D object
			compositing.
		<p align="center">
			<img src="./assets/real_world/bunny/obj.png" width="30%">
			<img src="./assets/real_world/bunny/dst_pixel_values.jpg" width="30%">
			<img src="./assets/real_world/bunny/post_comp.jpg" width="30%">
		<p align="center">
			<img src="./assets/real_world/cylinder/obj.jpg" width="30%">
			<img src="./assets/real_world/cylinder/dst_pixel_values.jpg" width="30%">
			<img src="./assets/real_world/cylinder/post_comp.jpg" width="30%">
		<p align="center">
			<img src="./assets/real_world/dog/obj_src_obj.jpg" width="30%">
			<img src="./assets/real_world/dog/dst_pixel_values.jpg" width="30%">
			<img src="./assets/real_world/dog/post_comp.jpg" width="30%">
	</table>

	<hr>

	<center>
		<h1>Demo Video</h1>
	</center>
	<table align=center hight='1200' width='800px'>
		<p align="center">
			<video width="100%" controls>
				<source src="./supp/videos/WACV_ZeroComp_demo_video.mp4" type="video/mp4">
				Your browser does not support the video tag.
			</video>
	</table>

	<hr>

	<div class="card mb-4 shadow-sm text-center">
		<h3 class="text-muted">Acknowledgements </h3>
		This research was supported by NSERC grants RGPIN 2020-04799 and ALLRP 586543-23, Mitacs and Depix. Computing
		resources were provided by the Digital Research Alliance of Canada. The authors thank Louis-Étienne Messier and
		Justine Giroux for their help as well as all members of the lab for discussions and proofreading help.
	</div>


</body>

</html>
<!DOCTYPE html>
<html lang="en" class="gr__vision_gel_ulaval_ca"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="author" content="">
    <title>A Deep Perceptual Measure for Lens and Camera Calibration</title>

    <!-- Bootstrap core CSS -->
    <link href="./static/bootstrap.min.css" rel="stylesheet">
    <!-- Bootstrap theme -->
    <link href="./static/bootstrap-theme.min.css" rel="stylesheet">

    <!-- Landing page theme -->
    <link href="./static/landing-page.css" rel="stylesheet">

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
</head>

<body data-gr-c-s-loaded="true" cz-shortcut-listen="true">

    <!-- Navigation -->
    <nav class="navbar navbar-default navbar-fixed-top topnav" role="navigation">
        <div class="container topnav">
            <!-- Collect the nav links, forms, and other content for toggling -->
            <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
                <ul class="nav navbar-nav navbar-right">
                    <li><a href="#paper">TPAMI'23</a></li>
                    <li><a href="#demo">Live demo</a></li>
                    <li><a href="#old">CVPR'18</a></li>
                </ul>
            </div>
            <!-- /.navbar-collapse -->
        </div>
        <!-- /.container -->
    </nav>


    <!-- Header -->
    <a name="intro"></a>
    <div class="intro-header">
        <div class="container">

            <div class="row">
                <div class="col-md-12">
                    <div class="intro-message">
                        <h1></h1>
                        <h1>A Deep Perceptual Measure for Lens and Camera Calibration</h1>
                        <p>Image editing and compositing have become ubiquitous in entertainment, from digital art to AR and VR experiences. To produce beautiful composites, the camera needs to be geometrically calibrated, which can be tedious and requires a physical calibration target. In place of the traditional multi-image calibration process, we propose to infer the camera calibration parameters such as pitch, roll, field of view, and lens distortion directly from a single image using a deep convolutional neural network. We train this network using automatically generated samples from a large-scale panorama dataset, yielding competitive accuracy in terms of standard L2 error. However, we argue that minimizing such standard error metrics might not be optimal for many applications. In this work, we investigate human sensitivity to inaccuracies in geometric camera calibration. To this end, we conduct a large-scale human perception study where we ask participants to judge the realism of 3D objects composited with correct and biased camera calibration parameters. Based on this study, we develop a new perceptual measure for camera calibration and demonstrate that our deep calibration network outperforms previous single-image based calibration methods both on standard metrics as well as on this novel perceptual measure. Finally, we demonstrate the use of our calibration network for several applications, including virtual object insertion, image retrieval, and compositing.</p>
                        <img class="center-block" src="./images/teaser-new.jpg" width="800px">
                    </div>
                </div>
            </div>

        </div>
        <!-- /.container -->

    </div>
    <!-- /.intro-header -->

    <!-- Page Content -->
	<a name="paper"></a>
    <div class="content-section-a">

        <div class="container">
            <div class="row">
                <div class="col-md-12">
                    <h2 class="section-heading">Paper (TPAMI 2023 version)</h2>

                    <a href="http://yannickhold.com">Yannick Hold-Geoffroy</a>, <a href="https://dompm.github.io/">Dominique Piché-Meunier</a>, <a href="https://research.adobe.com/person/kalyan-sunkavalli/">Kalyan Sunkavalli</a>, Jean-Charles Bazin, <a href="https://rameau-fr.github.io">François Rameau</a>, and <a href="http://vision.gel.ulaval.ca/~jflalonde/">Jean-François Lalonde</a> <br/>

                    A Deep Perceptual Measure for Lens and Camera Calibration <br/>

		    IEEE Transactions on Pattern Analysis and Machine Intelligence, <i>to appear</i>, 2023 <br/>

                    [<a href="https://arxiv.org/abs/2208.12300">arXiv pre-print</a>]

                    <br><br>

                    <h4>Supplementary material</h4>

                    We provide additional results in <a href="./supp_mat/main_supp.pdf">this supplementary document</a>.
                </div>
            </div>

        </div>
        <!-- /.container -->

    </div>
    

    <a name="demo"></a>
    <div class="content-section-b">
        <div class="container">

            <div class="row">
                <div class="col-md-12">
                    <div class="clearfix"></div>
                    <h2 class="section-heading">Live demo</h2>

                    <p>We have two different versions of our most recent (TPAMI 2023) approach: 
                        <ul>
                            <li><a href="http://rachmaninoff.gel.ulaval.ca:8004">With a ResNet backbone (as in the paper)</a></li>
                            <li><a href="http://rachmaninoff.gel.ulaval.ca:8005">With a more recent ConvNeXt backbone</a></li>
                        </ul>
                    </p>

                </div>
            </div>

        </div>
        <!-- /.container -->
    </div>


    <a name="old"></a>
    <div class="content-section-a">

        <div class="container">
            <div class="row">
                <div class="col-md-12">
                    <h2 class="section-heading">Paper (CVPR 2018 version)</h2>

                    Yannick Hold-Geoffroy, <a href="https://research.adobe.com/person/kalyan-sunkavalli/">Kalyan Sunkavalli</a>, Jonathan Eisenmann, <a href="https://research.adobe.com/person/matt-fisher/">Matt Fisher</a>, Emiliano Gambaretto, <a href="https://research.adobe.com/person/sunil-hadap/">Sunil Hadap</a>, and <a href="http://vision.gel.ulaval.ca/~jflalonde/">Jean-François Lalonde</a> <br/>

                    A Perceptual Measure for Deep Single Image Camera Calibration <br/>

                    IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2018. <br/>

                    [<a href="https://arxiv.org/abs/1712.01259">arXiv pre-print</a>]

                    <br><br>

                    <div style="text-align:center;">
                    <a href="https://arxiv.org/abs/1712.01259">
                    <img src="./images/thumbnails.jpg" width="850">
                    </a>
                    </div><br/>

                    <h4>Supplementary material</h4>

                    We provide additional results in <a href="./supp_mat/index.html">this supplementary page</a>.
				</div>
            </div>

        </div>
        <!-- /.container -->

    </div>
    
    <div class="content-section-b">
    <div class="container"><div class="row">
    <div class="col-md-5">
        <h2 class="section-heading">Poster (CVPR 2018)</h2>
        
        <p>You can download the poster presented at CVPR 2018 in <a href="./poster/YANNICK_HOLD_GEOFFROY_CVPR18_poster.pdf">PDF</a> format. </p>
        
    </div>
    <div class="col-md-5 col-md-offset-1">
    	<a href="./poster/YANNICK_HOLD_GEOFFROY_CVPR18_poster.pdf"><img src="./images/poster.jpg" width="350"></a>
    </div>
    
    </div></div>
    </div>

	<div class="content-section-a">
	    <div class="container">
		<div class="row">
			<div class="col-md-12">
	        <!--<div class="clearfix"></div>-->
	        <h2 class="section-heading">Acknowledgements</h2>

	        <p>The authors gratefully acknowledge the following funding sources: </p>
		<ul>
		<li>NSERC Discovery GRANT RGPIN-2014-05314</li>
		<li>Korea NRF grant NRF-2017R1C1B5077030</li>
		<li>FRQ-NT Ph.D. scholarship to Yannick Hold-Geoffroy</li>
		<li>NSERC USRA to Dominique Piché-Meunier</li>
		<li>A generous donation from Adobe to J-F Lalonde and J-C Bazin</li>
		<li>NVIDIA Corporation with the donation of the Tesla K40 and Titan X GPUs used for this research.</li>
		<li>REPARTI Strategic Network</li>
		</ul>
        	</div>
    	</div>
        <br>
        <div class="row">
        	<div class="col-md-5">
                <img src="./images/ulaval-logo-350.png" height="150px" alt="Ulaval logo">
    	</div>
	<div class="col-md-5 col-md-offset-1" style="text-align: center;">
	    	<img src="./images/adobe-logo.png" height="150px" alt="Adobe logo">
	</div>
        </div>

        </div>
        <!-- /.container -->
	
    </div>
    <!-- /.content-section-b -->
    

    <!-- Footer -->
    <footer>
        <div class="container">
            <div class="row">
                <div class="col-lg-12">
                    <p class="copyright text-muted small">The documents contained in these
                    directories are included by the contributing authors as a means to
                    ensure timely dissemination of scholarly and technical work on a
                    non-commercial basis. Copyright and all rights therein are maintained
                    by the authors or by other copyright holders, notwithstanding that
                    they have offered their works here electronically. It is understood
                    that all persons copying this information will adhere to the terms and
                    constraints invoked by each author's copyright. These works may not be
                    reposted without the explicit permission of the copyright holder,
                    except when identified by Creative Commons License 2.0, in which case
                    the license applies to both the original and modified versions of the
                    images.</p>
                </div>
            </div>
        </div>
    </footer>

    <!-- jQuery -->
    <script src="./static/jquery-3.1.1.min.js"></script>

    <!-- Bootstrap Core JavaScript -->
    <script src="./static/bootstrap.min.js"></script>

</body></html>
